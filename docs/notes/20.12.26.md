# 20.12.26

### Updated Plans

Constraint: I can only fetch 200 `TimeEntry`s from `CoreData` at a time

- this limit is self imposed
- in the future, I hope to push this indexing into a Background process, so being memory conscious should pay off



Worst Case Scenario: the user batch updates 200+ previously indexed `TimeEntry`s at once

- this might happen if, say, the user batch removing a tag, or batch fixing typos

- all the entries need to have their `representative` updated

- I can't set `lastIndexed` to `Date()`, since not everything was updated
- I can't leave the `lastIndexed` alone, otherwise all 200+ entries will be picked up again in the next operation



Solution:

0. always prioritize entries that have no `representative`

1. if everything has a `representative`, fetch `TimeEntry`s sorted by 
   1. `.updated`
   2. `.id` (guaranteed unique) 

2. after indexing, save the last entry's `updated` and `id`, and go from there

this should allow me to gradually sweep over all updated entries in a predictable manner that ensures they are re-indexed exactly once.



### Notes

- TIL you can use `NSPersistentContainer`'s `.performBackgroundTask` to do `CoreData` work in the background!
  - obviously we still need to do this manually with `Combine` chains, but in a big function it saves some headache
- take note of batch insertions into CoreData. This may help us to improve loading performance when we grab a week's worth of `TimeEntry`s
  - Unfortunately it is explicitly stated that this does not update relationships; since I need to set Tag and Project, that's a non-starter
- TIL about derived attributes in Core Data, covered in [this](https://developer.apple.com/videos/play/wwdc2019/230) WWDC talk at 21:00, and also discussed [here](https://www.avanderlee.com/core-data/derived-attributes-optimise-fetch-performance/)